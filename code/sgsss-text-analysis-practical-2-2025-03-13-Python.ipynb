{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![SGSSS Logo](../img/SGSSS_Stacked.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Text Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "## Introduction\n",
    "\n",
    "Computational methods are transforming research practice across the disciplines. For social scientists these methods offer a number of valuable opportunities, including creating new datasets from digital sources; unearthing new insights and avenues for research from existing data sources; and improving the accuracy and efficiency of fundamental research activities.\n",
    "\n",
    "In this lesson we introduce and apply a range of text analysis techniques to social science data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Aims\n",
    "\n",
    "This lesson has two aims:\n",
    "1. Demonstrate how to use Python to analyse text data relating to charitable activities.\n",
    "2. Cultivate your computational thinking skills through coding examples. In particular, how to define and solve a data preprocessing problem using a computational method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Lesson details\n",
    "\n",
    "* **Level**: Introductory\n",
    "* **Time**: 40-60 minutes\n",
    "* **Pre-requisites**: None\n",
    "* **Audience**: Researchers and analysts from any disciplinary background\n",
    "* **Learning outcomes**:\n",
    "    1. Understand and apply common text analysis techniques to social science data.\n",
    "    2. Be able to use Python for performing text analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Guide to using this resource\n",
    "\n",
    "This learning resource was built using <a href=\"https://jupyter.org/\" target=_blank>Jupyter Notebook</a>, an open-source software application that allows you to mix code, results and narrative in a single document. As <a href=\"https://jupyter4edu.github.io/jupyter-edu-book/\" target=_blank>Barba et al. (2019)</a> espouse:\n",
    "> In a world where every subject matter can have a data-supported treatment, where computational devices are omnipresent and pervasive, the union of natural language and computation creates compelling communication and learning opportunities.\n",
    "\n",
    "If you are familiar with Jupyter notebooks then skip ahead to the main content (*How do we prepare social science data for text analysis?*). Otherwise, the following is a quick guide to navigating and interacting with the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Interaction\n",
    "\n",
    "**You only need to execute the code that is contained in sections which are marked by `In []`.**\n",
    "\n",
    "To execute a cell, click or double-click the cell and press the `Run` button on the top toolbar (you can also use the keyboard shortcut Shift + Enter).\n",
    "\n",
    "Try it for yourself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Enter your name and press enter:\")\n",
    "name = input()\n",
    "print(\"\\r\")\n",
    "print(\"Hello {}, enjoy learning more about Python and web-scraping!\".format(name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Learn more\n",
    "\n",
    "Jupyter notebooks provide rich, flexible features for conducting and documenting your data analysis workflow. To learn more about additional notebook features, we recommend working through some of the <a href=\"https://github.com/darribas/gds19/blob/master/content/labs/lab_00.ipynb\" target=_blank>materials</a> provided by Dani Arribas-Bel at the University of Liverpool. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do we analyse social science text data?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a wide array of text analysis techniques that we could apply in our research:\n",
    "* **Descriptive inference:** how to characterise text; vector space model, bag of words, (dis)similarity measures, diversity, complexity, style, bursts.\n",
    "* **Supervised techniques:** dictionaries, sentiment analysis, categorising.\n",
    "* **Unsupervised techniques:** cluster analysis, PCA, topic modelling, embeddings. (Spirling, 2022)\n",
    "\n",
    "To say nothing of using Generative AI or Large Language Models (LLMs) to conduct these analyses on our behalf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson we focus on a number of common and often key analytical approaches:\n",
    "* Bag of words summaries and visualisations e.g., word clouds\n",
    "* Similarity metrics e.g., cosine similarity\n",
    "* Discriminating words e.g., Mutual Information and Fightin' Words\n",
    "\n",
    "We will cover the following topics in a later lesson:\n",
    "* Topic modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Preliminaries\n",
    "\n",
    "First we need to ensure Python has the functionality it needs for text analysis. As you will see, it needs quite a bit of extra functionality, so this may take some time to install / import depending on your machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install additional packages - only run once per machine\n",
    "!pip install autocorrect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Packages for general data and file management:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Packages for processing text data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk                       # get nltk \n",
    "from nltk import word_tokenize    # and some of its key functions\n",
    "from nltk import sent_tokenize\n",
    "from nltk import FreqDist\n",
    "\n",
    "from autocorrect import Speller   # things we need for spell checking\n",
    "check = Speller(lang='en')\n",
    "\n",
    "nltk.download('stopwords') # additional words or dictionaries we can use to check our documents against\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('webtext')\n",
    "nltk.download('words')\n",
    "\n",
    "from nltk.corpus import words     # list of valid English words\n",
    "english_words = set(words.words())\n",
    "\n",
    "from nltk.corpus import stopwords # list of common words that are not substantively informative e.g., \"the\"\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "from nltk.corpus import wordnet                    # functions we need for lemmatising\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "\n",
    "from nltk.stem.porter import PorterStemmer         # function we need for stemming\n",
    "porter = PorterStemmer()\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer # function we need for converting text to numeric\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # function we need for converting text to numeric\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "print(\"Succesfully imported necessary modules\")    # The print statement is just a bit of encouragement!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Packages for analysing text data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity # for calculating document similarity\n",
    "from wordcloud import WordCloud # for producing word clouds of DTMs\n",
    "import matplotlib.pyplot as plt # for data visualisation\n",
    "from sklearn.feature_selection import mutual_info_classif # for calculating mutual information score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A second important preliminary step is to import the text data you will be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = \"https://raw.githubusercontent.com/SGSSSonline/text-analysis-summer-school-2025/refs/heads/main/data/acnc-overseas-activities-2022.csv\" # define file to be imported\n",
    "\n",
    "data = pd.read_csv(infile, encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"activity_desc\"].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "###  Create Document Term Matrix\n",
    "\n",
    "You have likely created and saved this in a previous lesson but let's start afresh just in case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "\n",
    "    # Tokenize the text and convert to lowercase\n",
    "    words = nltk.word_tokenize(text)\n",
    "    lower_words = [word.lower() for word in words]\n",
    "    #print(lower_words)\n",
    "\n",
    "    # Remove punctuation and numbers\n",
    "    a_words = [word for word in lower_words if word.isalpha()]\n",
    "    #print(\"Alpha words: \",a_words)\n",
    "\n",
    "    # Lemmatise words\n",
    "    lemmed_words = [lemmatizer.lemmatize(word) for word in a_words]\n",
    "    #print(\"Lemmed words: \",lemmed_words)\n",
    "    \n",
    "    # Remove non-English words\n",
    "    e_words = [word for word in lemmed_words if word in english_words]\n",
    "    #print(\"English words: \", e_words)\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    new_stop_words = [\"registered\", \"registration\", \"company\", \"number\", \"australia\", \n",
    "                      \"australian\", \"report\", \"charity\", \"charities\", \"charitable\", \"year\", \n",
    "                      \"end\", \"statement\", \"statements\", \"trustee\", \"trustees\", \"trust\", \"overseas\",\n",
    "                     \"international\", \"support\", \"fund\", \"provide\", \"provision\", \"activity\", \"activities\",\n",
    "                     \"providing\", \"provided\", \"program\", \"programme\", \"project\"]\n",
    "    stop_words.update(new_stop_words)\n",
    "    s_words = [word for word in e_words if word not in stop_words]\n",
    "    #print(\"Stop words: \", s_words)\n",
    "\n",
    "    # Stem words\n",
    "    #stemmed_words = [porter.stem(word) for word in p_words]\n",
    "\n",
    "    # Remove words with less than three characters\n",
    "    clean_words = [word for word in s_words if len(str(word)) > 2]\n",
    "\n",
    "    return ' '.join(clean_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean text using function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure text column is valid\n",
    "data[\"activity_desc\"] = data[\"activity_desc\"].astype(str)\n",
    "data = data.dropna(subset=[\"activity_desc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"clean_text\"] = data[\"activity_desc\"].apply(preprocess_text)\n",
    "data[[\"abn\", \"activity_desc\", \"clean_text\"]].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create list of documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to loop over every row in the dataset and extract the charity unique id and the cleaned activity description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [(row[\"abn\"], row[\"clean_text\"]) for _, row in data.iterrows()]\n",
    "documents[0:5] # view first five elements in list of documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract just the cleaned text for converting to DTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = [text for _, text in documents]\n",
    "text_data[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Document-Term Matrix using a Count or TF-IDF vectoriser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\r",
    "bow = vectorizer.fit_transform(text_data)\n",
    "terms = vectorizer.get_feature_names_out() # extract unique terms in corpus (vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorizer = TfidfVectorizer()\n",
    "#bow = vectorizer.fit_transform(text_data)\n",
    "#terms = vectorizer.get_feature_names_out() # extract unique terms in corpus (vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DTM into a Pandas DataFrame\n",
    "dtm = pd.DataFrame(bow.toarray(), columns=vectorizer.get_feature_names_out(), index=[doc_id for doc_id, _ in documents])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pd.set_option('display.max_rows', None) # change display options\n",
    "pd.set_option('display.max_columns', None) # change display options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive inference"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descriptive inference in text analysis refers to the process of summarizing and identifying patterns, structures, and key characteristics in textual data without making causal claims (Grimmer & Stewart, 2013). There are many approaches we could take but in this lesson we will focus on:\n",
    "* Bag of words summaries and visualisations e.g., word clouds\n",
    "* Similarity metrics e.g., cosine similarity\n",
    "* Discriminating words e.g., Mutual Information and Fightin' Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple summaries of documents and terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A DTM represents a corpus as a series of rows and columns:\n",
    "* Each row represent a document in the corpus\n",
    "* Each column represents a term in the corpus\n",
    "* Each cell represents the frequency (weighted if tf-idf vectoriser was used) each term appears in each document\n",
    "\n",
    "The DTM offers us the ability to apply linear algebra to text and produce summaries across documents (e.g., how many times does a particular term appear in the corpus overall?) and within documents (e.g., how many terms does a document contain?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute row totals (sum of term frequencies per document)\n",
    "row_totals = dtm.sum(axis=1)\n",
    "\n",
    "# Compute column totals (sum of term frequencies per term across documents)\n",
    "column_totals = dtm.sum(axis=0)\n",
    "\n",
    "# Convert both to data frames\n",
    "dtm_row_totals = pd.DataFrame(row_totals, columns=[\"Document Totals\"])\n",
    "dtm_row_totals.index.name = \"abn\" # rename index as \"abn\" (unique charity id)\n",
    "dtm_row_totals = dtm_row_totals.reset_index() # convert index to column\n",
    "\n",
    "dtm_col_totals = pd.DataFrame(column_totals, columns=[\"Term Totals\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_row_totals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can go back to the DTM and look at the terms for a specific document as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_value = 11000761571  # Pick a unique id of a document\n",
    "\n",
    "# Filter the row using .loc[] and select only columns with nonzero values\n",
    "dtm.loc[[index_value], dtm.loc[index_value] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce summary statistics\n",
    "dtm_row_totals[\"Document Totals\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a summary of how long each document is (at least after preprocessing). That allows us to do some useful analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_row_totals['Document Totals'].hist(bins=10, edgecolor='black', figsize=(8, 5))\n",
    "plt.xlabel('Total number of terms in document')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of total document terms')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION:** What shape distribution - in broad terms - do the document totals have?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK:** Change the number of bins in the histogram and recreate the plot. How does the shape of the distribution change?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about the frequency of terms across the entire corpus, not just within a document?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_col_totals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK:** Produce summary statistics and a histogram for the term totals. Write a summary of the results. (*See a simple solution at the end of this notebook*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSERT CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Clouds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A word cloud is a simple visualisation of a bag of words representation of a corpus. It displays the terms in a corpus in accordance to how frequent the term appears: common terms are shown in a larger font and near the centre of the visualisation, while rare terms are shown in a smaller font and near the edges of the visualisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute word frequencies from the DTM by summing across rows (or down columns)\n",
    "word_frequencies = dtm.sum(axis=0).to_dict()\n",
    "\n",
    "# Generate the word cloud from DTM word frequencies\n",
    "wordcloud = WordCloud(width=800, height=400, background_color=\"white\").generate_from_frequencies(word_frequencies)\n",
    "\n",
    "# Display the word cloud\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION:** Write a short summary of the results of the word cloud. What can we say about the activities of overseas charities? Do the results point to any overlooked preprocessing work we needed to do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Dis)similarity metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An oft-posed question in text analysis is: how different or similar are documents in a corpus? For example, do they use similar terms and in similar frequencies or proportions? A robust and common metric that helps us answer these types of questions is **Cosine Similarity**. This is a measure of how similar two vectors (rows) in a DTM are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by calculating this measure for all pairs of documents in the DTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim_matrix = cosine_similarity(dtm)\n",
    "cosine_sim_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is difficult to read in this format so let's convert it to a more usable state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame for better visualization\n",
    "cosine_sim_df = pd.DataFrame(cosine_sim_matrix, index=dtm.index, columns=dtm.index)\n",
    "cosine_sim_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's much better. We have retained the document ids (unique charity number) so we can make easier comparisons between documents. This format should be familiar by now: it is a matrix just like a DTM is. Instead now we have a DDM (Document Document Matrix) where the rows and columns are both documents and the cells are cosine similarity scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION:** How do you interpret the diagonal values in the similarity matrix as all equalling 1?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can select particular pairs of documents and their cosine similarity score as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim_df.loc[11095489197, 99821785872] # select a cell in the matrix for two documents using their unique ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These documents are very different as the cosine similarity score is very close to zero. We should validate whether this is informative by looking at the original documents (activity descriptions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"activity_desc\"].loc[data[\"abn\"] == 11095489197].tolist() # convert to list for easier viewing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"activity_desc\"].loc[data[\"abn\"] == 99821785872].tolist() # convert to list for easier viewing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION:** Do you agree with the cosine similarity score that these documents are very different?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK:** Select a different pair of documents and compare their similarity scores and original document text. (Hint: you can see the full list of unique document ids by running `cosine_sim_df.index.tolist()`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSERT CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at pairs of documents can be interesting but is unlikely to be the focus on your analysis. Instead you are likely interested in summaries of cosine similarity across documents e.g., which documents have the highest / lowest average similarity score? We can use our techniques from earlier to achieve this i.e., calculating row summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute row means (mean of similarity scores per document)\n",
    "cosine_sim_df[\"Avg similarity score\"] = cosine_sim_df.mean(axis=1)\n",
    "cosine_sim_df[\"Avg similarity score\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION:** How different are activity descriptions of overseas charities?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK:** Create a histogram of the `Avg similarity score` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSERT CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminating words"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea with this analytical approach is to identify words that characterise the language use in a group of documents in the corpus (Grimmer et al., 2022). In essence, there may be words that are more prevalent in certain types of documents than others e.g., do large charities describe their overseas activities differently to medium or small organisations? The overarching aim is to be able to explain / predict documents belonging to certain categories (as opposed to uncovering what these categories or groups are)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mutual Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to implement this approach we need information from the DTM (the term frequencies) and the original data (the charity types). This helps us answer the question: are there terms that are more associated with large or medium charities compared to small organisations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the index into a column so we can merge charity size information\n",
    "dtm_mi = dtm # create a new version of DTM\n",
    "dtm_mi = dtm_mi.reset_index() # convert index to column\n",
    "dtm_mi.rename(columns={\"index\": \"abn\"}, inplace=True) # rename index as \"abn\" (unique charity id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_mi.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge charity size information from original data\n",
    "dtm_mi = dtm_mi.merge(data[[\"abn\", \"charitysize\"]], on=\"abn\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the \"charitysize\" column as numerical labels\n",
    "charitysize_labels = dtm_mi[\"charitysize\"].astype(\"category\").cat.codes\n",
    "\n",
    "# Compute Mutual Information scores for each term in the DTM\n",
    "mi_scores = mutual_info_classif(dtm_mi.iloc[:, 1:-1], charitysize_labels, discrete_features=True)\n",
    "\n",
    "# Create a DataFrame for Mutual Information Scores\n",
    "mi_df = pd.DataFrame({\"Term\": dtm_mi.columns[1:-1], \"Mutual Information\": mi_scores})\n",
    "\n",
    "# Sort by highest MI score\n",
    "mi_df = mi_df.sort_values(by=\"Mutual Information\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us a list of mutual information scores for terms in the corpus, where higher values indicate greater usefulness in distinguishing between documents. From the analysis above we can see that the term \"country\" is the most useful for distinguishing the documents between different size charities. However we do not know if this term is particularly associated with a given charity size (e.g., it is large charities that mainly use the term?). Therefore we need to compute the mutual information scores for each charity size separately and compare. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = dtm_mi[\"charitysize\"].unique()  # Get unique class names\n",
    "mi_results = {}\n",
    "\n",
    "for cls in class_labels:\n",
    "    # Convert multi-class labels into binary (1 for current class, 0 for others)\n",
    "    binary_labels = (dtm_mi[\"charitysize\"] == cls).astype(int)\n",
    "    \n",
    "    # Compute MI scores\n",
    "    mi_scores = mutual_info_classif(dtm_mi.iloc[:, 1:-1], binary_labels, discrete_features=True)\n",
    "    \n",
    "    # Store results in dictionary\n",
    "    mi_results[cls] = mi_scores\n",
    "\n",
    "# Convert to DataFrame\n",
    "mi_df = pd.DataFrame(mi_results, index=dtm_mi.columns[1:-1])\n",
    "mi_df.columns.name = \"Charity Size\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be difficult to read so let's sort by highest score for each charity size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change display settings to avoid scientific notation\n",
    "pd.set_option(\"display.float_format\", \"{:.4f}\".format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by highest MI score for small charities\n",
    "mi_df_small = mi_df.sort_values(by=\"Small\", ascending=False)\n",
    "mi_df_small.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by highest MI score for medium charities\n",
    "mi_df_medium = mi_df.sort_values(by=\"Medium\", ascending=False)\n",
    "mi_df_medium.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by highest MI score for medium charities\n",
    "mi_df_large = mi_df.sort_values(by=\"Large\", ascending=False)\n",
    "mi_df_large.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some potentially insightful differences: small and medium charities use words like \"school\" and \"partner\" much more than larger organisations, while the latter use words like \"equality\", \"inclusion\" and \"research\" more than their smaller counterparts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION:** Compare the top five distinguishing terms for each charity size. What do you notice? Are there any particular terms you think are noteworthy or indicative of real differences in the types of activities of different charities?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fightin' Words"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or \"Feature Weighting using Log-Odds Ratio with Informative Dirichlet Priors\" to give it its proper title. These are words that are overrepresented in one document compared to another. The Fightin' Words approach is particularly useful for analysing differences in word usage between two documents (Monroe et al., 2008), as it takes into account the extent to which words are used in documents, not just whether they are present or not (like in Mutual Information scores). \n",
    "\n",
    "The calculation of the Fightin' Words score is a bit complicated but essentially z-scores are generated which allow us to say whether certain words are **statistically significantly** to be appear in certain groups of documents than others.\n",
    "\n",
    "To make the analysis simpler we will divide documents into two categories (or classes): those written by small charities and those written by medium or large charities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the index into a column so we can merge charity size information\n",
    "dtm_fw = dtm # create a new version of DTM\n",
    "dtm_fw = dtm_fw.reset_index() # convert index to column\n",
    "dtm_fw.rename(columns={\"index\": \"abn\"}, inplace=True) # rename index as \"abn\" (unique charity id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge charity size information from original data\n",
    "dtm_fw = dtm_fw.merge(data[[\"abn\", \"charitysize\"]], on=\"abn\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_fw = dtm_fw.set_index(\"abn\")\n",
    "dtm_fw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure 'charitysize' is a string column\n",
    "dtm_fw[\"charitysize\"] = dtm_fw[\"charitysize\"].astype(str)\n",
    "\n",
    "# Create binary class labels: 'small' vs. 'medium/large'\n",
    "dtm_fw[\"binary_charitysize\"] = dtm_fw[\"charitysize\"].apply(lambda x: \"small\" if x == \"Small\" else \"medium_large\")\n",
    "\n",
    "# Identify term columns (excluding metadata)\n",
    "term_columns = dtm_fw.columns.difference([\"charitysize\", \"binary_charitysize\"])\n",
    "\n",
    "# Ensure term columns are numeric\n",
    "dtm_fw[term_columns] = dtm_fw[term_columns].apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "# Drop any remaining non-numeric values (optional)\n",
    "dtm_fw.dropna(inplace=True)\n",
    "\n",
    "# Compute word counts for each class\n",
    "word_counts = dtm_fw.groupby(\"binary_charitysize\")[term_columns].sum()\n",
    "\n",
    "# Apply Dirichlet prior smoothing (Laplace smoothing with Î±=1)\n",
    "alpha = 1  # Smoothing parameter\n",
    "word_probs = (word_counts + alpha) / (word_counts.sum(axis=1) + alpha * len(term_columns)).values[:, None]\n",
    "\n",
    "# Compute log-odds ratio\n",
    "log_odds_ratio = np.log(word_probs.loc[\"small\"]) - np.log(word_probs.loc[\"medium_large\"])\n",
    "\n",
    "# Compute variance using Dirichlet prior\n",
    "variance = (1 / (word_counts.loc[\"small\"] + alpha)) + (1 / (word_counts.loc[\"medium_large\"] + alpha))\n",
    "std_dev = np.sqrt(variance)\n",
    "\n",
    "# Compute z-scores (Fightin' Words metric)\n",
    "z_scores = log_odds_ratio / std_dev\n",
    "\n",
    "# Create a DataFrame for Fightin' Words Scores\n",
    "fw_df = pd.DataFrame({\"Term\": term_columns, \"Log-Odds Ratio\": log_odds_ratio, \"Z-Score\": z_scores})\n",
    "fw_df = fw_df.sort_values(by=\"Z-Score\", ascending=False)  # Sort by highest Z-score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of Mathematics in the above code, let's focus on the interpretation instead. We are interested in z-scores greater than 2 i.e., those are **statistically significantly** more likely to be found in the activity descriptions of small charities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fw_df.head(20) # top 20 z-scores (most discriminating words for small charities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversely, we can also look at negative z-scores to see which words are **statistically significantly** more likely to be found in the activity descriptions of medium/large charities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fw_df.tail(20) # bottom 20 z-scores (most discriminating words for medium/large charities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks considerably more insightful than the Mutual Information (MI) approach. Small charities seem to discuss issues relating to schooling (\"pupil\", \"school\", \"scholarship\") much more frequently than medium or large organisations. Conversely they are less likely to operate at a global scale according to their word usage (e.g., they don't tend to use words like \"across\", \"country\" or \"world\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION:** Are there meaningful words that distinguish the activity descriptions of small, medium and large charities? Can you make any substantive conclusions about differences in the nature of overseas activities by charity size? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are generally not interested in z-scores within -2 and +2 as these are likely to be found at the same rate in the documents of small, medium and large charities; however we can look at them as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fw_df[(fw_df[\"Z-Score\"] >= -2) & (fw_df[\"Z-Score\"] <= 2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK:** Change the range of the z-scores so that you examine terms with values between -.5 and .5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What have we learned?\n",
    "\n",
    "Let's recap what key skills and techniques we've learned:\n",
    "* **How to import modules**. You will usually need to import modules into Python to support your work. Python does come with some methods and functions that are ready to use straight away, but for text analysis tasks you'll almost certainly need to import some additional modules.\n",
    "* **How to make descriptive inferences from text data**. There are a number of common and key analytical techniques that can yield substantive insight into key features of documents.\n",
    "* **How to do all of the above in an efficient, clear and effective manner**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "These are but a selection of the analytical techniques at your displosal; however they are common and often key ones in text analysis projects. In the next practical we will focus on more substantively rich analytical techniques, specifically sentiment analysis and topic modelling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a DTM / DFM using the other file in the data folder (*acnc-overseas-activities-2021.csv*) and apply the analytical techniques demonstrated in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSERT CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSERT CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The solution is provided at the end of this course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Producing summaries and visualisations of term totals in corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_col_totals[\"Term Totals\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_col_totals['Term Totals'].hist(bins=500, edgecolor='black', figsize=(8, 5))\n",
    "plt.xlabel('Total number of occurances of terms in corpus')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of total occurances of terms')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort and select top 25 terms\n",
    "sorted_terms = sorted(column_totals.items(), key=lambda x: x[1], reverse=True)[:25]\n",
    "terms, frequencies = zip(*sorted_terms)\n",
    "\n",
    "# Plot bar chart\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(terms, frequencies)\n",
    "plt.xlabel(\"Terms\")\n",
    "plt.ylabel(\"Total Frequency\")\n",
    "plt.title(\"Top 25 Most Common Terms in DTM\")\n",
    "plt.xticks(rotation=45, ha=\"right\")  # Rotate labels for better readability\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "--END OF FILE--"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "256px",
    "width": "221px"
   },
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
